{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0eec04",
   "metadata": {},
   "source": [
    "# Data Preprocessing for ToN-IoT Network Dataset\n",
    "Tiền xử lý dữ liệu cho các mô hình phát hiện tấn công."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ee536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888452b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1. Read & basic cleaning ----------\n",
    "df = pd.read_csv(\"D:/vhproj/Ton_IoT/data/Ton_IoT_Network.csv\")\n",
    "df.replace('-', np.nan, inplace=True)\n",
    "for c in df.select_dtypes(include=['object']).columns:\n",
    "    df[c] = df[c].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2. Make sure label is numeric ----------\n",
    "if df['label'].dtype == object:\n",
    "    try:\n",
    "        df['label'] = pd.to_numeric(df['label'], errors='coerce')\n",
    "    except Exception:\n",
    "        df['label'] = df['label'].map({'normal':0, 'attack':1}).astype(float)\n",
    "df = df[~df['label'].isna()].copy()\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdaea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3. Feature selection: drop noisy columns ----------\n",
    "drop_cols = ['ts']\n",
    "possible_drop = ['src_ip', 'dst_ip', 'http_uri', 'http_user_agent', 'ssl_subject', 'ssl_issuer',\n",
    "                 'weird_name', 'weird_addl', 'weird_notice']\n",
    "for c in possible_drop:\n",
    "    if c in df.columns:\n",
    "        drop_cols.append(c)\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4. Convert numeric-like columns to numeric ----------\n",
    "for col in df.columns:\n",
    "    if col == 'label':\n",
    "        continue\n",
    "    if df[col].dtype == object:\n",
    "        parsed = pd.to_numeric(df[col], errors='coerce')\n",
    "        frac_numeric = parsed.notna().mean()\n",
    "        if frac_numeric >= 0.7:\n",
    "            df[col] = parsed\n",
    "        else:\n",
    "            df[col] = df[col].replace('nan', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb481bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5. Split features / label ----------\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print('Train size:', X_train_raw.shape, 'Test size:', X_test_raw.shape)\n",
    "print('Label distribution (train):\\n', y_train.value_counts(normalize=True))\n",
    "print('Label distribution (test):\\n', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 6. Preprocessing functions ----------\n",
    "def preprocess_fit_transform(X_train):\n",
    "    X = X_train.copy()\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    num_imputer = SimpleImputer(strategy='median')\n",
    "    X_num = pd.DataFrame(num_imputer.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=numeric_cols, index=X.index)\n",
    "    low_card_cols = []\n",
    "    high_card_cols = []\n",
    "    freq_maps = {}\n",
    "    for c in cat_cols:\n",
    "        nunique = X[c].nunique(dropna=True)\n",
    "        if nunique <= 20:\n",
    "            low_card_cols.append(c)\n",
    "        else:\n",
    "            high_card_cols.append(c)\n",
    "            freq = X[c].fillna('::MISSING::').value_counts(normalize=True).to_dict()\n",
    "            freq_maps[c] = freq\n",
    "    if low_card_cols:\n",
    "        X_low = pd.get_dummies(X[low_card_cols].fillna('::MISSING::'), dummy_na=False, drop_first=False)\n",
    "    else:\n",
    "        X_low = pd.DataFrame(index=X.index)\n",
    "    X_high = pd.DataFrame(index=X.index)\n",
    "    for c in high_card_cols:\n",
    "        X_high[c + '_freq'] = X[c].fillna('::MISSING::').map(freq_maps[c]).fillna(0.0)\n",
    "    X_proc = pd.concat([X_num_scaled, X_low, X_high], axis=1)\n",
    "    meta = {\n",
    "        'numeric_cols': numeric_cols,\n",
    "        'num_imputer': num_imputer,\n",
    "        'scaler': scaler,\n",
    "        'low_card_cols': low_card_cols,\n",
    "        'high_card_cols': high_card_cols,\n",
    "        'freq_maps': freq_maps,\n",
    "        'onehot_columns': X_low.columns.tolist(),\n",
    "    }\n",
    "    return X_proc, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13068ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transform(X_test, meta):\n",
    "    X = X_test.copy()\n",
    "    numeric_cols = meta['numeric_cols']\n",
    "    num_imputer = meta['num_imputer']\n",
    "    scaler = meta['scaler']\n",
    "    for c in numeric_cols:\n",
    "        if c not in X.columns:\n",
    "            X[c] = np.nan\n",
    "    X_num = pd.DataFrame(num_imputer.transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "    X_num_scaled = pd.DataFrame(scaler.transform(X_num), columns=numeric_cols, index=X.index)\n",
    "    low_card_cols = meta['low_card_cols']\n",
    "    if low_card_cols:\n",
    "        X_low = pd.get_dummies(X[low_card_cols].fillna('::MISSING::'), dummy_na=False, drop_first=False)\n",
    "        for c in meta['onehot_columns']:\n",
    "            if c not in X_low.columns:\n",
    "                X_low[c] = 0\n",
    "        X_low = X_low[meta['onehot_columns']]\n",
    "    else:\n",
    "        X_low = pd.DataFrame(index=X.index)\n",
    "    X_high = pd.DataFrame(index=X.index)\n",
    "    for c in meta['high_card_cols']:\n",
    "        fmap = meta['freq_maps'].get(c, {})\n",
    "        X_high[c + '_freq'] = X[c].fillna('::MISSING::').map(fmap).fillna(0.0)\n",
    "    X_proc = pd.concat([X_num_scaled, X_low, X_high], axis=1)\n",
    "    return X_proc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
